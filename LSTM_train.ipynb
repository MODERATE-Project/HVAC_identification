{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a85f480-3cf6-48ee-8744-c6689281300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/softwarestack/miniconda3/envs/datascience/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, os, joblib\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch, joblib, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "## define the directory of current file \n",
    "directory = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80958e45-98a4-4c4e-8824-0cedc4f89c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348681/1201258112.py:11: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  time_series_df.index = pd.date_range(start=\"2023-01-01\", periods=time_series_df.shape[0], freq=\"H\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 1882400 sequences across 1300 IDs\n",
      "✅ Train/test split complete\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load data\n",
    "time_series_df = pd.read_pickle(os.path.join(directory, 'all_time_series_Consumption.pkl'))\n",
    "time_series_df.set_index('Datetime', inplace=True)\n",
    "labels_df_org = pd.read_pickle(os.path.join(directory, 'labels_df.pkl'))[['ID', 'Category']]\n",
    "\n",
    "# Assign hourly datetime index (ensure proper format)\n",
    "time_series_df.index = pd.date_range(start=\"2023-01-01\", periods=time_series_df.shape[0], freq=\"H\")\n",
    "\n",
    "# Daily aggregation\n",
    "daily_df = time_series_df.resample(\"D\").agg(['mean', 'max', 'std', 'skew'])\n",
    "daily_df.columns.set_names([\"id\", \"stat\"], inplace=True)\n",
    "daily_df.columns = pd.MultiIndex.from_tuples([(str(id_), stat) for id_, stat in daily_df.columns])  # Convert ID to str\n",
    "\n",
    "# Prepare label encoder\n",
    "labels_df = labels_df_org.set_index('ID')\n",
    "labels_df.index = labels_df.index.astype(str)  # Ensure matching with daily_df\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels_df['Category'])\n",
    "\n",
    "# Sequence creation\n",
    "sequence_length = 12\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for id_ in labels_df.index:\n",
    "    try:\n",
    "        ts = daily_df.loc[:, id_]  # ✅ MultiIndex selection\n",
    "    except KeyError:\n",
    "        print(f\"Skipping ID {id_} — not found in daily_df\")\n",
    "        continue\n",
    "    \n",
    "    ts_values = ts.values\n",
    "    \n",
    "    if ts_values.shape[0] < sequence_length:\n",
    "        print(f\"Skipping ID {id_} — not enough days for sequences\")\n",
    "        continue\n",
    "\n",
    "    label = labels_df.loc[id_, 'Category']\n",
    "    encoded_label = label_encoder.transform([label])[0]\n",
    "\n",
    "    for i in range(len(ts_values) - sequence_length):\n",
    "        X.append(ts_values[i:i+sequence_length])\n",
    "        y.append(encoded_label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"✅ Created {len(X)} sequences across {len(set(labels_df.index))} IDs\")\n",
    "\n",
    "# Train/test split\n",
    "if len(X) > 0:\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y if len(set(y)) > 1 else None, random_state=42\n",
    "    )\n",
    "    print(\"✅ Train/test split complete\")\n",
    "else:\n",
    "    raise ValueError(\"❌ No sequences were created. Check sequence length or data coverage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6764d24-1ea6-4e5d-8bdd-bc8c2b0e4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# ---------------------\n",
    "# 1. Define your model class (same as training)\n",
    "# ---------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, bidirectional):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n",
    "                            batch_first=True, dropout=dropout, bidirectional=bidirectional)\n",
    "        multiplier = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(hidden_dim * multiplier, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "#########\n",
    "best_params = {  # \n",
    "    'hidden_dim': 254,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.24846495923913972,\n",
    "    'bidirectional': False,\n",
    "    'input_dim': 4,  # daily features: mean, max, std, skew\n",
    "    'output_dim': 5  # number of classes\n",
    "}\n",
    "\n",
    "model = LSTMModel(\n",
    "    input_dim=best_params['input_dim'],\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    output_dim=best_params['output_dim'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout'],\n",
    "    bidirectional=best_params['bidirectional']\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load (os.path.join(directory, 'best_lstm_model.pt')))\n",
    "model.eval()\n",
    "\n",
    "# Also reload your label encoder (or refit it if needed)\n",
    "\n",
    "label_encoder = joblib.load((os.path.join(directory, 'label_encoder.pkl')))\n",
    "\n",
    "# Use it for transforming or inverse transforming\n",
    "label = label_encoder.inverse_transform([1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb8c58e5-b7c9-4fdb-bcaa-8f0c2a28ad2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 44\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# usage:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# raw_time_series = pd.read_pickle(\"new_raw_hourly_data.pkl\")  # shape: (timestamps x IDs)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#preds = predict_labels(prepare_sequences_from_raw(raw_time_series))\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#for id_, labels in preds.items():\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#     print(f\"ID {id_}: Predicted labels for {len(labels)} sequences → {labels}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mpredict_labels\u001b[0;34m(sequences_dict)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_labels\u001b[39m(sequences_dict):\n\u001b[1;32m     29\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m id_, sequences \u001b[38;5;129;01min\u001b[39;00m \u001b[43msequences_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     31\u001b[0m         X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(sequences), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# 3. Prepare new raw input (e.g., hourly DataFrame)\n",
    "# ---------------------\n",
    "def prepare_sequences_from_raw(raw_df, sequence_length=12):\n",
    "    raw_df.index = pd.to_datetime(raw_df.index)\n",
    "    daily_df = raw_df.resample(\"D\").agg(['mean', 'max', 'std', 'skew'])\n",
    "\n",
    "    daily_df.columns.set_names([\"id\", \"stat\"], inplace=True)\n",
    "    daily_df.columns = pd.MultiIndex.from_tuples([(str(id_), stat) for id_, stat in daily_df.columns])\n",
    "\n",
    "    sequences = {}\n",
    "    for id_ in raw_df.columns:\n",
    "        try:\n",
    "            ts = daily_df.loc[:, str(id_)]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        ts_values = ts.values\n",
    "        if ts_values.shape[0] < sequence_length:\n",
    "            continue\n",
    "        sequences[id_] = [\n",
    "            ts_values[i:i+sequence_length] for i in range(len(ts_values) - sequence_length + 1)\n",
    "        ]\n",
    "    return sequences\n",
    "\n",
    "# ---------------------\n",
    "# 4. Predict for each ID\n",
    "# ---------------------\n",
    "def predict_labels(sequences_dict):\n",
    "    predictions = {}\n",
    "    for id_, sequences in sequences_dict.items():\n",
    "        X_tensor = torch.tensor(np.array(sequences), dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            logits = model(X_tensor)\n",
    "            pred_indices = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            pred_labels = label_encoder.inverse_transform(pred_indices)\n",
    "            predictions[id_] = pred_labels\n",
    "    return predictions\n",
    "\n",
    "# ---------------------\n",
    "# usage:\n",
    "# ---------------------\n",
    "# raw_time_series = pd.read_pickle(\"new_raw_hourly_data.pkl\")  # shape: (timestamps x IDs)\n",
    "#preds = predict_labels(prepare_sequences_from_raw(raw_time_series))\n",
    "preds = predict_labels(X_test)\n",
    "\n",
    "#for id_, labels in preds.items():\n",
    "#     print(f\"ID {id_}: Predicted labels for {len(labels)} sequences → {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390e9ee-e4ef-47fd-941b-4bbf3b7cec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, labels, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i + seq_length])\n",
    "        y_seq.append(labels[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "sequence_length = 12\n",
    "X_full, y_full = create_sequences(time_series_scaled.T, labels_encoded, sequence_length)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_full, y_full, test_size=0.2, stratify=y_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a0c0d-5bc3-42f5-a171-4cea135aeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def predict_from_tensor(model, X_array, device=\"cpu\", batch_size=32):\n",
    "    \"\"\"\n",
    "    Predicts from a numpy array using a trained model in batches.\n",
    "    Avoids GPU memory overflow.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataset = TensorDataset(torch.tensor(X_array, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch[0].to(device)\n",
    "            logits = model(inputs)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    return np.array(all_preds)\n",
    "y_pred_indices = predict_from_tensor(model, X_test, device=\"cpu\", batch_size=32)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778537ad-239a-4b7b-9044-495606a5d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert y_test to label names\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels, labels=label_encoder.classes_)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: Classification report\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datascience)",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
